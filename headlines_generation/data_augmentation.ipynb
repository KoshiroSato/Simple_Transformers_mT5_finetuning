{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"data_augmentation.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","execution_count":null,"source":["import random\n","import numpy as np\n","import pandas as pd\n","from time import sleep\n","from textblob import TextBlob\n","from textblob.translate import NotTranslated\n","import torch\n","from nlpaug.augmenter.word import ContextualWordEmbsAug\n","from tqdm.notebook import tqdm"],"outputs":[],"metadata":{"id":"fafed647"}},{"cell_type":"code","execution_count":null,"source":["data = pd.read_csv('../data/headlines_generation_corpus/train.csv')"],"outputs":[],"metadata":{"id":"2064712c"}},{"cell_type":"code","execution_count":null,"source":["## Aug1: Sentence Shuffle\n","def random_sentence_shuffle(text, random_state=42):\n","    '''\n","    文章をスプリットし、無作為にシャッフル\n","    '''\n","    random.seed(random_state)\n","    text = text.split('。')\n","    random.shuffle(text)\n","    text = ' '.join(text)\n","    return text\n","\n","def sentence_shuffle(text):\n","    '''\n","    example:                           \n","    [sentenceA, sentenceB, sentenceC] --apply--> [sentenceC, sentenceA, sentenceB] \n","    '''\n","    text_arr = np.array(text.split('。')[:-1])\n","    shuffled = np.roll(text_arr, 1).tolist()\n","    shuffled_text = ' '.join(shuffled)\n","    return shuffled_text\n","\n","def apply_sentenceShuffle(df, shuffle=False):\n","    new_df = df.copy()\n","    if shuffle == True:\n","        new_df['input_text'] = pd.Series([str(random_sentence_shuffle(value)) for value in df['input_text']])\n","    else:\n","        new_df['input_text'] = pd.Series([str(sentence_shuffle(value)) for value in df['input_text']])\n","    return new_df\n","\n","\n","## Aug2: Back Translation\n","def back_translation(text):\n","    '''\n","    訓練データを\n","    日本語 → 英語 → 日本語の流れで\n","    逆翻訳する\n","    '''\n","    textblob = TextBlob(text)\n","    # HTTP Error 429回避のため、sleep\n","    try:\n","        textblob = textblob.translate(to='en')\n","        sleep(0.4)\n","        textblob = textblob.translate(to='ja')\n","        sleep(0.4)\n","        return textblob\n","    except NotTranslated:\n","        pass\n","    except RemoteDisconnected:\n","        print('RemoteDisconnected!')\n","    \n","def apply_backTranslation(df):\n","    new_df = df.copy()\n","    new_df['input_text'] = pd.Series([str(back_translation(value)) for value in tqdm(df['input_text'])])\n","    return new_df\n","\n","# not use\n","# ## Aug3: Contextual Word Embedded Augmentation by BERT\n","# def word_embedded_aug(df):\n","#     '''\n","#     BERTによる類似単語埋め込み（置き換え）増強\n","#     '''\n","#     params = {\n","#         'model_path': 'cl-tohoku/bert-base-japanese-char-whole-word-masking',\n","#         'aug_p': 0.1,\n","#         'batch_size': 32,\n","#         'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n","#     }\n","#     aug_df = df.copy()\n","#     aug = ContextualWordEmbsAug(**params)\n","#     aug_df['input_text'] = [aug.augment(text) for text in tqdm(df['input_text'])]\n","#     # denoising\n","#     aug_df['input_text'] = aug_df['input_text'].apply(lambda x: x.replace(' ',''))\n","#     aug_df['include_unk'] = aug_df['input_text'].str.contains('[UNK]')\n","#     aug_df = aug_df.query('include_unk == False')\n","#     aug_df = aug_df.drop(['include_unk'], axis=1)\n","#     return aug_df"],"outputs":[],"metadata":{"id":"2d060427"}},{"cell_type":"code","execution_count":null,"source":["ss_aug_data = apply_sentenceShuffle(data, shuffle=False)\n","bt_aug_data = apply_backTranslation(data)"],"outputs":[],"metadata":{"id":"115e89b1"}},{"cell_type":"code","execution_count":null,"source":["ss_aug_data.to_csv('../data/headlines_generation_corpus/sentence_shuffle_aug_data.csv', index=False)\n","bt_aug_data.to_csv('../data/headlines_generation_corpus/back_translation_aug_data.csv', index=False)"],"outputs":[],"metadata":{"id":"4444cb5c"}}]}